{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[4, 2])\n",
    "Y = tf.placeholder(tf.float32, shape=[4, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두개의 입력값을 받는 두개의 뉴런을 만듬\n",
    "W1 = tf.Variable(tf.random_uniform([2, 2]))\n",
    "# 각 뉴런은 한개의 편향값을 가짐\n",
    "B1 = tf.Variable(tf.zeros([2]))\n",
    "# 출력값으로 Z를 리턴함. sigmoid(W1 * X + B1)\n",
    "Z = tf.sigmoid(tf.matmul(X, W1) + B1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z를 입력값으로 받는 하나의 뉴런을 두번째 히든 레이어에 만듬\n",
    "W2 = tf.Variable(tf.random_uniform([2, 1]))\n",
    "# 뉴런은 한개의 편향값\n",
    "B2 = tf.Variable(tf.zeros([1]))\n",
    "# 출력값으로 Y_hat을 리턴 sigmoid(W2 * Z + B2)\n",
    "Y_hat = tf.sigmoid(tf.matmul(Z, W2) + B2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실함수는 크로스 엔트로피\n",
    "loss = tf.reduce_mean(-1 * ((Y * tf.log(Y_hat)) + ((1 - Y) * tf.log(1.0 - Y_hat))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적화는 경사하강법\n",
    "train_step = tf.train.GradientDescentOptimizer(0.05).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터\n",
    "train_X = [[0, 0], [0, 1], [1, 0], [1, 1]]\n",
    "train_Y = [[0], [1], [1], [0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data: [[0, 0], [0, 1], [1, 0], [1, 1]]\n",
      "Epoch:  0\n",
      "Output:  [[0.61849993]\n",
      " [0.62813413]\n",
      " [0.66040957]\n",
      " [0.6682143 ]]\n",
      "Epoch:  5000\n",
      "Output:  [[0.3030844 ]\n",
      " [0.5491264 ]\n",
      " [0.5952925 ]\n",
      " [0.58471954]]\n",
      "Epoch:  10000\n",
      "Output:  [[0.08208672]\n",
      " [0.9107308 ]\n",
      " [0.9102463 ]\n",
      " [0.11688337]]\n",
      "Epoch:  15000\n",
      "Output:  [[0.03301819]\n",
      " [0.97234917]\n",
      " [0.9722385 ]\n",
      " [0.03187104]]\n",
      "Result:  [[0.02009783]\n",
      " [0.9842589 ]\n",
      " [0.98421025]\n",
      " [0.0174408 ]]\n"
     ]
    }
   ],
   "source": [
    "# 텐서플로 매개변수 초기화\n",
    "init = tf.global_variables_initializer()\n",
    "# 학습 시작\n",
    "with tf.Session() as sess:\n",
    "    # 매개변수 초기화\n",
    "    sess.run(init)\n",
    "    print(f'train data: {train_X}')\n",
    "    # 2만번의 학습 진행\n",
    "    for i in range(20000):\n",
    "        sess.run(train_step, feed_dict={X: train_X, Y: train_Y})\n",
    "        if i % 5000 == 0:\n",
    "            print('Epoch: ',i)\n",
    "            print('Output: ',sess.run(Y_hat, feed_dict={X: train_X, Y: train_Y}))\n",
    "    print('Result: ',sess.run(Y_hat, feed_dict={X: train_X, Y: train_Y}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
