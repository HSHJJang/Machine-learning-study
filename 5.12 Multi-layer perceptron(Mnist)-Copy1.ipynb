{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://raw.githubusercontent.com/captainchargers/deeplearning/master/img/dropout.png\" width=\"500\" height=\"250\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://raw.githubusercontent.com/captainchargers/deeplearning/master/img/dropout.png\", width=500, height=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검증 데이터 분리\n",
    "x_val  = x_train[50000:60000]\n",
    "x_train = x_train[0:50000]\n",
    "y_val  = y_train[50000:60000]\n",
    "y_train = y_train[0:50000]\n",
    "# train 50000, val 10000, test 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://raw.githubusercontent.com/captainchargers/deeplearning/master/img/reshape_mnist.png\" width=\"500\" height=\"250\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 구조 변경\n",
    "Image(url= \"https://raw.githubusercontent.com/captainchargers/deeplearning/master/img/reshape_mnist.png\", width=500, height=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784)\n",
      "(10000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.reshape(50000, 784)\n",
    "x_val = x_val.reshape(10000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_val.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 정규화\n",
    "x_train = x_train.astype('float32')\n",
    "x_val = x_val.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "gray_scale = 255\n",
    "x_train /= gray_scale\n",
    "x_val /= gray_scale\n",
    "x_test /= gray_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding으로 변환\n",
    "num_classes = 10\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_val = tf.keras.utils.to_categorical(y_val, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://raw.githubusercontent.com/captainchargers/deeplearning/master/img/dropout.png\" width=\"500\" height=\"250\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 이거 구현할거임\n",
    "Image(url= \"https://raw.githubusercontent.com/captainchargers/deeplearning/master/img/dropout.png\", width=500, height=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y = tf.placeholder(tf.float32, [None, 10])\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아래 하든 레이어2(h2)에 드랍아웃을 적용합니다. keep_prob의 값은 모델을 학습 또는 테스트할 때 결정합니다.\n",
    "def mlp(x):\n",
    "    # hidden layer 1\n",
    "    w1 = tf.Variable(tf.random_uniform([784, 256]))\n",
    "    b1 = tf.Variable(tf.zeros([256]))\n",
    "    h1 = tf.nn.relu(tf.matmul(x, w1) + b1)\n",
    "    # hidden layer 2\n",
    "    w2 = tf.Variable(tf.random_uniform([256, 128]))\n",
    "    b2 = tf.Variable(tf.zeros([128]))\n",
    "    h2 = tf.nn.relu(tf.matmul(h1, w2) + b2)\n",
    "    h2_drop = tf.nn.dropout(h2, keep_prob)\n",
    "    # output layer\n",
    "    w3 = tf.Variable(tf.random_uniform([128, 10]))\n",
    "    b3 = tf.Variable(tf.zeros([10]))\n",
    "    logits = tf.matmul(h2_drop, w3) + b3\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = mlp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(\\\n",
    "                                                                   logits=logits, labels=y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_op = tf.train.AdamOptimizer(learning_rate=0.01).minimize(loss_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Add ops to save and restore all the variables\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# train hyperparameters\n",
    "epoch_cnt = 300\n",
    "batch_size = 1000\n",
    "iteration = len(x_train) // batch_size\n",
    "\n",
    "# 5번 연속으로 검증 정확도가 최고정확도보다 낮을경우 조기 종료\n",
    "earlystop_threshold = 5\n",
    "earlystop_cnt = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train acc: 0.10202000290155411, val acc: 0.10320000350475311\n",
      "epoch: 1, train acc: 0.47411999106407166, val acc: 0.48910000920295715\n",
      "epoch: 2, train acc: 0.5546000003814697, val acc: 0.5756000280380249\n",
      "epoch: 3, train acc: 0.6157199740409851, val acc: 0.6294999718666077\n",
      "epoch: 4, train acc: 0.6685400009155273, val acc: 0.6858999729156494\n",
      "epoch: 5, train acc: 0.7100800275802612, val acc: 0.7269999980926514\n",
      "epoch: 6, train acc: 0.7397199869155884, val acc: 0.7565000057220459\n",
      "epoch: 7, train acc: 0.7646999955177307, val acc: 0.7800999879837036\n",
      "epoch: 8, train acc: 0.7850000262260437, val acc: 0.8001000285148621\n",
      "epoch: 9, train acc: 0.8030800223350525, val acc: 0.8192999958992004\n",
      "epoch: 10, train acc: 0.8195800185203552, val acc: 0.8352000117301941\n",
      "epoch: 11, train acc: 0.8339599967002869, val acc: 0.8476999998092651\n",
      "epoch: 12, train acc: 0.8446599841117859, val acc: 0.854200005531311\n",
      "epoch: 13, train acc: 0.8552600145339966, val acc: 0.863099992275238\n",
      "epoch: 14, train acc: 0.8641600012779236, val acc: 0.8705000281333923\n",
      "epoch: 15, train acc: 0.8716800212860107, val acc: 0.8756999969482422\n",
      "epoch: 16, train acc: 0.877839982509613, val acc: 0.8784999847412109\n",
      "epoch: 17, train acc: 0.8841999769210815, val acc: 0.8841000199317932\n",
      "epoch: 18, train acc: 0.8887799978256226, val acc: 0.8885999917984009\n",
      "epoch: 19, train acc: 0.8937399983406067, val acc: 0.8906000256538391\n",
      "epoch: 20, train acc: 0.8977400064468384, val acc: 0.8939999938011169\n",
      "epoch: 21, train acc: 0.9007400274276733, val acc: 0.8968999981880188\n",
      "epoch: 22, train acc: 0.9049000144004822, val acc: 0.8996999859809875\n",
      "epoch: 23, train acc: 0.9086999893188477, val acc: 0.9021000266075134\n",
      "epoch: 24, train acc: 0.9106600284576416, val acc: 0.90420001745224\n",
      "epoch: 25, train acc: 0.9134600162506104, val acc: 0.9052000045776367\n",
      "epoch: 26, train acc: 0.9150599837303162, val acc: 0.9075999855995178\n",
      "epoch: 27, train acc: 0.9171599745750427, val acc: 0.9090999960899353\n",
      "epoch: 28, train acc: 0.9199000000953674, val acc: 0.9107999801635742\n",
      "epoch: 29, train acc: 0.9220399856567383, val acc: 0.9132000207901001\n",
      "epoch: 30, train acc: 0.9230800271034241, val acc: 0.9132999777793884\n",
      "epoch: 31, train acc: 0.9251599907875061, val acc: 0.9146999716758728\n",
      "epoch: 32, train acc: 0.9268800020217896, val acc: 0.9144999980926514\n",
      "overfitting warning: 0\n",
      "epoch: 33, train acc: 0.9298200011253357, val acc: 0.916700005531311\n",
      "epoch: 34, train acc: 0.9304999709129333, val acc: 0.9165999889373779\n",
      "overfitting warning: 0\n",
      "epoch: 35, train acc: 0.9330599904060364, val acc: 0.917900025844574\n",
      "epoch: 36, train acc: 0.9353200197219849, val acc: 0.9193000197410583\n",
      "epoch: 37, train acc: 0.9361600279808044, val acc: 0.9190999865531921\n",
      "overfitting warning: 0\n",
      "epoch: 38, train acc: 0.9374799728393555, val acc: 0.9205999970436096\n",
      "epoch: 39, train acc: 0.9384999871253967, val acc: 0.9205999970436096\n",
      "epoch: 40, train acc: 0.9397199749946594, val acc: 0.9214000105857849\n",
      "epoch: 41, train acc: 0.9409999847412109, val acc: 0.9218000173568726\n",
      "epoch: 42, train acc: 0.9418799877166748, val acc: 0.9226999878883362\n",
      "epoch: 43, train acc: 0.9431999921798706, val acc: 0.9247000217437744\n",
      "epoch: 44, train acc: 0.9445599913597107, val acc: 0.9243999719619751\n",
      "overfitting warning: 0\n",
      "epoch: 45, train acc: 0.9458799958229065, val acc: 0.9259999990463257\n",
      "epoch: 46, train acc: 0.9472399950027466, val acc: 0.9272000193595886\n",
      "epoch: 47, train acc: 0.9478200078010559, val acc: 0.9279999732971191\n",
      "epoch: 48, train acc: 0.9491999745368958, val acc: 0.9287999868392944\n",
      "epoch: 49, train acc: 0.9495800137519836, val acc: 0.929099977016449\n",
      "epoch: 50, train acc: 0.9507799744606018, val acc: 0.9287999868392944\n",
      "overfitting warning: 0\n",
      "epoch: 51, train acc: 0.9516199827194214, val acc: 0.9301999807357788\n",
      "epoch: 52, train acc: 0.9524800181388855, val acc: 0.9311000108718872\n",
      "epoch: 53, train acc: 0.9528999924659729, val acc: 0.9297999739646912\n",
      "overfitting warning: 0\n",
      "epoch: 54, train acc: 0.954259991645813, val acc: 0.9311000108718872\n",
      "epoch: 55, train acc: 0.9550999999046326, val acc: 0.9312000274658203\n",
      "epoch: 56, train acc: 0.9556800127029419, val acc: 0.9314000010490417\n",
      "epoch: 57, train acc: 0.9565600156784058, val acc: 0.9334999918937683\n",
      "epoch: 58, train acc: 0.9573000073432922, val acc: 0.9312999844551086\n",
      "overfitting warning: 0\n",
      "epoch: 59, train acc: 0.9572399854660034, val acc: 0.9326000213623047\n",
      "epoch: 60, train acc: 0.9583600163459778, val acc: 0.933899998664856\n",
      "epoch: 61, train acc: 0.9589599967002869, val acc: 0.9330000281333923\n",
      "overfitting warning: 0\n",
      "epoch: 62, train acc: 0.9603599905967712, val acc: 0.9344000220298767\n",
      "epoch: 63, train acc: 0.9604200124740601, val acc: 0.9336000084877014\n",
      "overfitting warning: 0\n",
      "epoch: 64, train acc: 0.9602800011634827, val acc: 0.9332000017166138\n",
      "epoch: 65, train acc: 0.9621400237083435, val acc: 0.9352999925613403\n",
      "epoch: 66, train acc: 0.9616000056266785, val acc: 0.9358000159263611\n",
      "epoch: 67, train acc: 0.9624000191688538, val acc: 0.9355000257492065\n",
      "overfitting warning: 0\n",
      "epoch: 68, train acc: 0.9634199738502502, val acc: 0.9362999796867371\n",
      "epoch: 69, train acc: 0.9643399715423584, val acc: 0.9352999925613403\n",
      "overfitting warning: 0\n",
      "epoch: 70, train acc: 0.9643599987030029, val acc: 0.9363999962806702\n",
      "epoch: 71, train acc: 0.9652199745178223, val acc: 0.9362999796867371\n",
      "overfitting warning: 0\n",
      "epoch: 72, train acc: 0.9657800197601318, val acc: 0.9379000067710876\n",
      "epoch: 73, train acc: 0.9652600288391113, val acc: 0.9381999969482422\n",
      "epoch: 74, train acc: 0.9665200114250183, val acc: 0.9377999901771545\n",
      "overfitting warning: 0\n",
      "epoch: 75, train acc: 0.966480016708374, val acc: 0.9362999796867371\n",
      "epoch: 76, train acc: 0.9670600295066833, val acc: 0.9366999864578247\n",
      "overfitting warning: 0\n",
      "epoch: 77, train acc: 0.9668599963188171, val acc: 0.9376999735832214\n",
      "epoch: 78, train acc: 0.9672600030899048, val acc: 0.9383000135421753\n",
      "epoch: 79, train acc: 0.9678999781608582, val acc: 0.9391999840736389\n",
      "epoch: 80, train acc: 0.9691799879074097, val acc: 0.9384999871253967\n",
      "overfitting warning: 0\n",
      "epoch: 81, train acc: 0.968940019607544, val acc: 0.9387999773025513\n",
      "epoch: 82, train acc: 0.9698200225830078, val acc: 0.9373999834060669\n",
      "overfitting warning: 0\n",
      "epoch: 83, train acc: 0.9701600074768066, val acc: 0.9394000172615051\n",
      "epoch: 84, train acc: 0.9713000059127808, val acc: 0.9398999810218811\n",
      "epoch: 85, train acc: 0.9711999893188477, val acc: 0.9394000172615051\n",
      "epoch: 86, train acc: 0.9710999727249146, val acc: 0.9381999969482422\n",
      "epoch: 87, train acc: 0.9719200134277344, val acc: 0.9391000270843506\n",
      "overfitting warning: 0\n",
      "epoch: 88, train acc: 0.9723399877548218, val acc: 0.9399999976158142\n",
      "epoch: 89, train acc: 0.9719600081443787, val acc: 0.9386000037193298\n",
      "epoch: 90, train acc: 0.9731600284576416, val acc: 0.9387999773025513\n",
      "overfitting warning: 0\n",
      "epoch: 91, train acc: 0.9732400178909302, val acc: 0.9395999908447266\n",
      "overfitting warning: 1\n",
      "epoch: 92, train acc: 0.9732000231742859, val acc: 0.9387999773025513\n",
      "epoch: 93, train acc: 0.9740399718284607, val acc: 0.9398999810218811\n",
      "overfitting warning: 0\n",
      "epoch: 94, train acc: 0.9739199876785278, val acc: 0.939300000667572\n",
      "epoch: 95, train acc: 0.9737600088119507, val acc: 0.9398999810218811\n",
      "epoch: 96, train acc: 0.9739000201225281, val acc: 0.9387000203132629\n",
      "overfitting warning: 0\n",
      "epoch: 97, train acc: 0.9757400155067444, val acc: 0.9395999908447266\n",
      "overfitting warning: 1\n",
      "epoch: 98, train acc: 0.9751999974250793, val acc: 0.9391999840736389\n",
      "epoch: 99, train acc: 0.9743000268936157, val acc: 0.9394999742507935\n",
      "epoch: 100, train acc: 0.9754999876022339, val acc: 0.941100001335144\n",
      "epoch: 101, train acc: 0.9757599830627441, val acc: 0.9413999915122986\n",
      "epoch: 102, train acc: 0.9754800200462341, val acc: 0.9420999884605408\n",
      "epoch: 103, train acc: 0.9771400094032288, val acc: 0.9419999718666077\n",
      "overfitting warning: 0\n",
      "epoch: 104, train acc: 0.9765999913215637, val acc: 0.9413999915122986\n",
      "epoch: 105, train acc: 0.9775599837303162, val acc: 0.9419000148773193\n",
      "overfitting warning: 0\n",
      "epoch: 106, train acc: 0.9771199822425842, val acc: 0.941100001335144\n",
      "epoch: 107, train acc: 0.9767799973487854, val acc: 0.9415000081062317\n",
      "epoch: 108, train acc: 0.9781399965286255, val acc: 0.9416999816894531\n",
      "overfitting warning: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 109, train acc: 0.9753599762916565, val acc: 0.9422000050544739\n",
      "epoch: 110, train acc: 0.9778599739074707, val acc: 0.9434000253677368\n",
      "epoch: 111, train acc: 0.9763200283050537, val acc: 0.9413999915122986\n",
      "epoch: 112, train acc: 0.9762600064277649, val acc: 0.9444000124931335\n",
      "epoch: 113, train acc: 0.9781399965286255, val acc: 0.9424999952316284\n",
      "overfitting warning: 0\n",
      "epoch: 114, train acc: 0.9777799844741821, val acc: 0.944100022315979\n",
      "epoch: 115, train acc: 0.9780200123786926, val acc: 0.9430999755859375\n",
      "overfitting warning: 0\n",
      "epoch: 116, train acc: 0.9777600169181824, val acc: 0.9430999755859375\n",
      "epoch: 117, train acc: 0.9760199785232544, val acc: 0.9408000111579895\n",
      "epoch: 118, train acc: 0.9777399897575378, val acc: 0.9437999725341797\n",
      "overfitting warning: 0\n",
      "epoch: 119, train acc: 0.9768000245094299, val acc: 0.9437000155448914\n",
      "epoch: 120, train acc: 0.975820004940033, val acc: 0.9429000020027161\n",
      "epoch: 121, train acc: 0.9783599972724915, val acc: 0.9448999762535095\n",
      "epoch: 122, train acc: 0.9782599806785583, val acc: 0.9430000185966492\n",
      "epoch: 123, train acc: 0.9797000288963318, val acc: 0.9435999989509583\n",
      "overfitting warning: 0\n",
      "epoch: 124, train acc: 0.9794399738311768, val acc: 0.9466999769210815\n",
      "epoch: 125, train acc: 0.9801200032234192, val acc: 0.944599986076355\n",
      "overfitting warning: 0\n",
      "epoch: 126, train acc: 0.9781799912452698, val acc: 0.9448000192642212\n",
      "epoch: 127, train acc: 0.9777600169181824, val acc: 0.9441999793052673\n",
      "epoch: 128, train acc: 0.9752399921417236, val acc: 0.9437000155448914\n",
      "epoch: 129, train acc: 0.9828199744224548, val acc: 0.9459999799728394\n",
      "overfitting warning: 0\n",
      "epoch: 130, train acc: 0.981220006942749, val acc: 0.9433000087738037\n",
      "epoch: 131, train acc: 0.9818400144577026, val acc: 0.9453999996185303\n",
      "overfitting warning: 0\n",
      "epoch: 132, train acc: 0.981440007686615, val acc: 0.941100001335144\n",
      "epoch: 133, train acc: 0.9813200235366821, val acc: 0.9447000026702881\n",
      "epoch: 134, train acc: 0.9826200008392334, val acc: 0.9452000260353088\n",
      "overfitting warning: 0\n",
      "epoch: 135, train acc: 0.9830999970436096, val acc: 0.9458000063896179\n",
      "overfitting warning: 1\n",
      "epoch: 136, train acc: 0.980139970779419, val acc: 0.9449999928474426\n",
      "epoch: 137, train acc: 0.9828000068664551, val acc: 0.9448999762535095\n",
      "overfitting warning: 0\n",
      "epoch: 138, train acc: 0.9797800183296204, val acc: 0.9420999884605408\n",
      "epoch: 139, train acc: 0.9804400205612183, val acc: 0.9451000094413757\n",
      "overfitting warning: 0\n",
      "epoch: 140, train acc: 0.9831399917602539, val acc: 0.9466999769210815\n",
      "epoch: 141, train acc: 0.9790599942207336, val acc: 0.9429000020027161\n",
      "epoch: 142, train acc: 0.9807199835777283, val acc: 0.9455999732017517\n",
      "overfitting warning: 0\n",
      "epoch: 143, train acc: 0.9789599776268005, val acc: 0.9441999793052673\n",
      "epoch: 144, train acc: 0.9855200052261353, val acc: 0.9470999836921692\n",
      "epoch: 145, train acc: 0.9826599955558777, val acc: 0.9447000026702881\n",
      "epoch: 146, train acc: 0.983680009841919, val acc: 0.9460999965667725\n",
      "overfitting warning: 0\n",
      "epoch: 147, train acc: 0.9851599931716919, val acc: 0.9470999836921692\n",
      "epoch: 148, train acc: 0.9850199818611145, val acc: 0.947700023651123\n",
      "epoch: 149, train acc: 0.9820399880409241, val acc: 0.9455999732017517\n",
      "epoch: 150, train acc: 0.9843800067901611, val acc: 0.9455000162124634\n",
      "overfitting warning: 0\n",
      "epoch: 151, train acc: 0.9848999977111816, val acc: 0.9470000267028809\n",
      "overfitting warning: 1\n",
      "epoch: 152, train acc: 0.9857400059700012, val acc: 0.9473000168800354\n",
      "overfitting warning: 2\n",
      "epoch: 153, train acc: 0.986240029335022, val acc: 0.9480999708175659\n",
      "epoch: 154, train acc: 0.9854599833488464, val acc: 0.947700023651123\n",
      "epoch: 155, train acc: 0.9869400262832642, val acc: 0.9523000121116638\n",
      "epoch: 156, train acc: 0.9873600006103516, val acc: 0.9496999979019165\n",
      "overfitting warning: 0\n",
      "epoch: 157, train acc: 0.9879599809646606, val acc: 0.9485999941825867\n",
      "overfitting warning: 1\n",
      "epoch: 158, train acc: 0.9874399900436401, val acc: 0.9513999819755554\n",
      "epoch: 159, train acc: 0.9864400029182434, val acc: 0.9498999714851379\n",
      "epoch: 160, train acc: 0.9870799779891968, val acc: 0.9491999745368958\n",
      "overfitting warning: 0\n",
      "epoch: 161, train acc: 0.9860600233078003, val acc: 0.949999988079071\n",
      "epoch: 162, train acc: 0.9865599870681763, val acc: 0.9513999819755554\n",
      "overfitting warning: 0\n",
      "epoch: 163, train acc: 0.9857199788093567, val acc: 0.948199987411499\n",
      "epoch: 164, train acc: 0.983780026435852, val acc: 0.9466000199317932\n",
      "epoch: 165, train acc: 0.9860000014305115, val acc: 0.949400007724762\n",
      "overfitting warning: 0\n",
      "epoch: 166, train acc: 0.9878799915313721, val acc: 0.9506999850273132\n",
      "overfitting warning: 1\n",
      "epoch: 167, train acc: 0.987820029258728, val acc: 0.9506999850273132\n",
      "epoch: 168, train acc: 0.9863200187683105, val acc: 0.9506999850273132\n",
      "epoch: 169, train acc: 0.9869999885559082, val acc: 0.9495000243186951\n",
      "overfitting warning: 0\n",
      "epoch: 170, train acc: 0.9869599938392639, val acc: 0.9510999917984009\n",
      "epoch: 171, train acc: 0.9876400232315063, val acc: 0.9510999917984009\n",
      "overfitting warning: 0\n",
      "epoch: 172, train acc: 0.9866399765014648, val acc: 0.9501000046730042\n",
      "epoch: 173, train acc: 0.987820029258728, val acc: 0.951200008392334\n",
      "overfitting warning: 0\n",
      "epoch: 174, train acc: 0.9876800179481506, val acc: 0.9538000226020813\n",
      "epoch: 175, train acc: 0.9889799952507019, val acc: 0.9523000121116638\n",
      "overfitting warning: 0\n",
      "epoch: 176, train acc: 0.9890199899673462, val acc: 0.9532999992370605\n",
      "overfitting warning: 1\n",
      "epoch: 177, train acc: 0.9895399808883667, val acc: 0.9537000060081482\n",
      "overfitting warning: 2\n",
      "epoch: 178, train acc: 0.9894599914550781, val acc: 0.9535999894142151\n",
      "epoch: 179, train acc: 0.9865400195121765, val acc: 0.9510999917984009\n",
      "epoch: 180, train acc: 0.9882400035858154, val acc: 0.9527999758720398\n",
      "overfitting warning: 0\n",
      "epoch: 181, train acc: 0.9840800166130066, val acc: 0.9510999917984009\n",
      "epoch: 182, train acc: 0.9875199794769287, val acc: 0.9526000022888184\n",
      "overfitting warning: 0\n",
      "epoch: 183, train acc: 0.9888200163841248, val acc: 0.9541000127792358\n",
      "epoch: 184, train acc: 0.9865800142288208, val acc: 0.9516000151634216\n",
      "epoch: 185, train acc: 0.9872999787330627, val acc: 0.9520999789237976\n",
      "overfitting warning: 0\n",
      "epoch: 186, train acc: 0.9897199869155884, val acc: 0.9539999961853027\n",
      "overfitting warning: 1\n",
      "epoch: 187, train acc: 0.9894199967384338, val acc: 0.9531000256538391\n",
      "epoch: 188, train acc: 0.9892600178718567, val acc: 0.9516000151634216\n",
      "epoch: 189, train acc: 0.9909800291061401, val acc: 0.9546999931335449\n",
      "epoch: 190, train acc: 0.9895399808883667, val acc: 0.9537000060081482\n",
      "epoch: 191, train acc: 0.9886999726295471, val acc: 0.9523000121116638\n",
      "epoch: 192, train acc: 0.9870799779891968, val acc: 0.9520000219345093\n",
      "epoch: 193, train acc: 0.9876400232315063, val acc: 0.9517999887466431\n",
      "overfitting warning: 0\n",
      "epoch: 194, train acc: 0.9905999898910522, val acc: 0.9535999894142151\n",
      "overfitting warning: 1\n",
      "epoch: 195, train acc: 0.9910200238227844, val acc: 0.9531999826431274\n",
      "overfitting warning: 2\n",
      "epoch: 196, train acc: 0.9904000163078308, val acc: 0.9546999931335449\n",
      "epoch: 197, train acc: 0.9889000058174133, val acc: 0.9537000060081482\n",
      "epoch: 198, train acc: 0.9922000169754028, val acc: 0.9559999704360962\n",
      "epoch: 199, train acc: 0.9921799898147583, val acc: 0.9574999809265137\n",
      "epoch: 200, train acc: 0.991599977016449, val acc: 0.9573000073432922\n",
      "overfitting warning: 0\n",
      "epoch: 201, train acc: 0.9922599792480469, val acc: 0.9577999711036682\n",
      "epoch: 202, train acc: 0.9890199899673462, val acc: 0.953000009059906\n",
      "epoch: 203, train acc: 0.9901999831199646, val acc: 0.954800009727478\n",
      "overfitting warning: 0\n",
      "epoch: 204, train acc: 0.9891800284385681, val acc: 0.9538000226020813\n",
      "epoch: 205, train acc: 0.9906600117683411, val acc: 0.9556000232696533\n",
      "overfitting warning: 0\n",
      "epoch: 206, train acc: 0.9899399876594543, val acc: 0.9574999809265137\n",
      "epoch: 207, train acc: 0.9886599779129028, val acc: 0.9545999765396118\n",
      "epoch: 208, train acc: 0.9894999861717224, val acc: 0.9555000066757202\n",
      "overfitting warning: 0\n",
      "epoch: 209, train acc: 0.9904599785804749, val acc: 0.9550999999046326\n",
      "overfitting warning: 1\n",
      "epoch: 210, train acc: 0.9916999936103821, val acc: 0.9574999809265137\n",
      "overfitting warning: 2\n",
      "epoch: 211, train acc: 0.9890999794006348, val acc: 0.9559999704360962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 212, train acc: 0.9899399876594543, val acc: 0.9570000171661377\n",
      "overfitting warning: 0\n",
      "epoch: 213, train acc: 0.9922800064086914, val acc: 0.9577999711036682\n",
      "epoch: 214, train acc: 0.9920799732208252, val acc: 0.957099974155426\n",
      "overfitting warning: 0\n",
      "epoch: 215, train acc: 0.9930400252342224, val acc: 0.9587000012397766\n",
      "epoch: 216, train acc: 0.9932600259780884, val acc: 0.9584000110626221\n",
      "overfitting warning: 0\n",
      "epoch: 217, train acc: 0.9909800291061401, val acc: 0.9567999839782715\n",
      "overfitting warning: 1\n",
      "epoch: 218, train acc: 0.991100013256073, val acc: 0.9578999876976013\n",
      "overfitting warning: 2\n",
      "epoch: 219, train acc: 0.9895200133323669, val acc: 0.9562000036239624\n",
      "epoch: 220, train acc: 0.9901999831199646, val acc: 0.955299973487854\n",
      "overfitting warning: 0\n",
      "epoch: 221, train acc: 0.9919800162315369, val acc: 0.9581999778747559\n",
      "overfitting warning: 1\n",
      "epoch: 222, train acc: 0.9921000003814697, val acc: 0.9591000080108643\n",
      "epoch: 223, train acc: 0.9933800101280212, val acc: 0.9603000283241272\n",
      "epoch: 224, train acc: 0.9943199753761292, val acc: 0.9589999914169312\n",
      "overfitting warning: 0\n",
      "epoch: 225, train acc: 0.99235999584198, val acc: 0.9563999772071838\n",
      "overfitting warning: 1\n",
      "epoch: 226, train acc: 0.9897199869155884, val acc: 0.9559000134468079\n",
      "epoch: 227, train acc: 0.9909399747848511, val acc: 0.9559000134468079\n",
      "overfitting warning: 0\n",
      "epoch: 228, train acc: 0.9920799732208252, val acc: 0.9569000005722046\n",
      "overfitting warning: 1\n",
      "epoch: 229, train acc: 0.9916200041770935, val acc: 0.9575999975204468\n",
      "overfitting warning: 2\n",
      "epoch: 230, train acc: 0.9916999936103821, val acc: 0.9556000232696533\n",
      "overfitting warning: 3\n",
      "epoch: 231, train acc: 0.9929400086402893, val acc: 0.9581999778747559\n",
      "overfitting warning: 4\n",
      "epoch: 232, train acc: 0.9926199913024902, val acc: 0.9571999907493591\n",
      "early stopped on 232\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "데이터를 모델에 입력시킬 때(feed), 드랍아웃이 있을 경우, 항상 keep_prob를 설정해주셔야합니다.\n",
    "학습 시, 10%의 드랍아웃을 하기 위해, keep_prob를 0.9로 설정합니다.\n",
    "테스트 시, 드랍 아웃을 사용하지 않을 것이므로, keep_prob를 1.0으로 설정합니다.\n",
    "\"\"\"\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    prev_train_acc = .0\n",
    "    max_val_acc = .0\n",
    "    for epoch in range(epoch_cnt):\n",
    "        avg_loss = 0.\n",
    "        start = 0; end = batch_size\n",
    "        for i in range(iteration):\n",
    "            _, loss = sess.run([train_op, loss_op],\n",
    "                              feed_dict={x: x_train[start:end],\n",
    "                                        y: y_train[start:end], keep_prob: 0.9})\n",
    "            start += batch_size; end += batch_size\n",
    "            # 학습 손실값 계산\n",
    "            avg_loss += loss / iteration\n",
    "            \n",
    "        # 모델 검증\n",
    "        preds = tf.nn.softmax(logits) # 소프트맥스 적용\n",
    "        correct_prediction = tf.equal(tf.argmax(preds, 1), tf.argmax(y, 1))\n",
    "        # 정확도 계산\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, 'float'))\n",
    "        # 학습 정확도 계산\n",
    "        cur_train_acc = accuracy.eval({x: x_train, y: y_train, keep_prob: 1.0})\n",
    "        # 검증 정확도 계산\n",
    "        cur_val_acc = accuracy.eval({x: x_val, y: y_val, keep_prob: 1.0})\n",
    "        \n",
    "        print(f'epoch: {epoch}, train acc: {cur_train_acc}, val acc: {cur_val_acc}')\n",
    "        \n",
    "        if cur_val_acc < max_val_acc:\n",
    "            if cur_train_acc > prev_train_acc or cur_train_acc > 0.99:\n",
    "                if earlystop_cnt == earlystop_threshold:\n",
    "                    print('early stopped on',epoch)\n",
    "                    break\n",
    "                else:\n",
    "                    print('overfitting warning:',earlystop_cnt)\n",
    "                    earlystop_cnt += 1\n",
    "            else:\n",
    "                earlystop_cnt = 0\n",
    "        else:\n",
    "            earlystop_cnt = 0\n",
    "            max_val_acc = cur_val_acc\n",
    "            # 검증 정확도 가장 높은 모델 저장\n",
    "            save_path = saver.save(sess, 'model/model.ckpt')\n",
    "        prev_train_acc = cur_train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model/model.ckpt\n",
      "[Test Accuracy] : 0.9593\n"
     ]
    }
   ],
   "source": [
    "# 테스트 시작\n",
    "with tf.Session() as sess:\n",
    "    # 검증 결과가 가장 높았던 모델 불러오기\n",
    "    saver.restore(sess, 'model/model.ckpt')\n",
    "    correct_prediction = tf.equal(tf.argmax(preds, 1), tf.argmax(y, 1))\n",
    "    # 정확도 계산\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, 'float'))\n",
    "    print(\"[Test Accuracy] :\", accuracy.eval({x: x_test, y: y_test, keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
